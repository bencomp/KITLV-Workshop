{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simpele zoekacties\n",
    "\n",
    "In dit tutorial vindt je uitleg over hoe je het corpus van \"Soldaat in Indonesie\" kunt doorzoeken op basis van Text & Data Mining. Er wordt hierbij gebruik gemaakt van de programmeertaal Python. Dit tutorial is echter geen basisintroductie tot programmeren in Python. De voorbeelden hieronder laten allen zien hoe je het corpus kunt doorzoeken met behup van bestaande modules en bibliotheken. Modules zijn kant en klare en herbruikbare ‘pakketjes’ code waarin specifieke functionaliteiten worden aangeboden. De meeste modules zijn generiek, en kunnen dus op verschillende datasets worden toegepast. \n",
    "\n",
    "In dit tutorial wordt onder meer gebruik gemaakt van de module  ‘os’. Deze module biedt een aantal functies waarmee je contact kunt maken met het besturingssysteem (de letters in 'os' staan voor 'operating system'). Met de functies in deze module kun je onder meer de inhoud van een map op je computer lezen. 'nltk' is eveneens een verzameling modules. De 'Natural Language Toolkit' is een verzameling functies die je kunnen helpen om de methodologie van Natural Language Processing toe te passen. Je kunt paragrafen in afzonderlijke zinnen, je kunt de stam van een woord of werkwoord als apart onderdeel in je resultaten te krijgen, of je kunt de computer vragen om grammaticale categorieen toe te kennen.\n",
    "\n",
    "De module kitlvTdm is specifiek ontwikkeld voor het KITLV. Deze module bevat een aantal basisoperaties op het gebied van Text & Data Mining.\n",
    "\n",
    "Voordat je van deze bestaande modules gebruik kunt maken moet je deze eerst importeren via het commando 'import'. In de cel hieronder worden alle benodigde modules geimporteerd. Ga met de cursor in dze cel staan, en klik daarna op [shift] + [Enter].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import isfile, join , isdir\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import xml.etree.ElementTree as ET\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from kitlvTdm import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wanneer de bovenstaande cel foutmeldingen oplevert kan dit mogelijk worden veroorzaakt doordat de modules ng niet zijn geinstalleerd. Modules kunnen namelijk alleen worden geimporteerd wanneer ze eerst zijn geinstalleerd. Modules en bibliotheken kunnen via de onderstaande commando's worden geinstalleerd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!conda install --yes --prefix {sys.prefix} os\n",
    "!conda install --yes --prefix {sys.prefix} nltk\n",
    "!conda install --yes --prefix {sys.prefix} wordcloud\n",
    "!conda install --yes --prefix {sys.prefix} matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De code laat zien hoe je op zoek kunt gaan naar egodocumenten die een bepaald trefwoord bevatten. Het woord dat gezocht moet worden moet worden opgegeven als waarde van de variable '*searchTerm*'. De onderstaande code zoekt naar egodocumenten waar het woord 'molukker' in voor komt. De waarde van de variabele '*searchTerm*', tussen de twee aanhalingstekens, kan worden aangepast. \n",
    "\n",
    "Er wordt in de onderstaande code gebruik gemaakt van de module 're', waarmee je kunt zoeken naar zogenaamde reuliere expressies of woordpatronen. Wanneer de code wordt uitgevoerd toont het programma een lijst van alle documenten waar de term die is opgegeven in voorkomt. \n",
    "\n",
    "In het corpus worden eigen codes gebruikt voor de gedigitaliseerde teksten. Via een bestand 'metadata.csv' worden de juiste titels bij deze codes gezocht. De waarde van de variable _searchTerm_ kan worden aangepast. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchTerm = 'molukker'\n",
    "\n",
    "print( 'The term \\'{}\\' occurs in the following titles:\\n'.format( searchTerm ) )\n",
    "\n",
    "for file in os.listdir( dir ):\n",
    "    if re.search( '[.]txt$' , file ):\n",
    "        book = open( join( dir , file ) )\n",
    "        if re.search( searchTerm , book.read() ):\n",
    "            print(  file + ': ' + showTitle( file )  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Om de relevante passages te bekijken kan gebruik worden gemaakt van een een concordantie (of een keyword-in-context-list). Dit is een lijst van alle fragmenten waar het genoemde trefwoord in voorkomt, met een vast aantal wooren voor en een vast aantal woorden na het trefwoord.\n",
    "\n",
    "In de onderstaande code moet er op de eerste plaats een zoekterm worden opgegeven, als waarde van de variabele *searchTerm*. De omvang van de context (het aantal woorden voor en na het trefwoord) moet worden vastgelegd via de variabele 'window'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchTerm = 'molukker'\n",
    "window = 1\n",
    "\n",
    "\n",
    "for file in os.listdir( dir ):\n",
    "    if re.search( '[.]txt$' , file ):\n",
    "        book = open( join( dir , file ) )\n",
    "        if re.search( searchTerm , book.read() , re.IGNORECASE ):\n",
    "            \n",
    "            print( '\\n\\nOccurrences in: ' + showTitle( file ) + '\\n\\n' )\n",
    "            matches = concordance( join( dir , file ) , regex , window )\n",
    "            for match in matches:\n",
    "                print(match + '\\n')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Net als bij een concordantie (zie hierboven) richt een collocatie-analyse zich op de context van specifieke zoektermen. Bij een collocatie-analyse worden alle woorden in de context geteld. Op deze manier kan er een beeld ontstaan van de woorden die veel in de omgeving van een specifieke zoekterm worden gebruikt. Variabele 'book' verwijst naar de tekst die moet worden doorzocht, 'searchTerm' is de term waarnaar wordt gezicht, en 'window' bepaalt het aantal woorden voor en na de opgegeven zoekterm. In de onderstaande code wordt ook de functie _removeStopwords()_ gebruikt. Deze functie heeft als effect dat veelvoorkomende woorden zonder veel betekenis (lidwoorden, voornaamwoorden, voorzetstel) buiten beschouwing worden gelaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book = '03390.txt'\n",
    "searchTerm = 'java'\n",
    "window = 30\n",
    "\n",
    "freq = collocation( join( dir , book ) , searchTerm , window )\n",
    "freq = removeStopwords( freq )\n",
    "\n",
    "sorted_f = sorted( freq , key=lambda x: freq[x])\n",
    "max = 30\n",
    "i = 0\n",
    "\n",
    "for f in reversed( sorted_f ):\n",
    "    i += 1\n",
    "    print( '{} =>  {}'.format( f , freq[f] ) )\n",
    "    if i == max:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De onderstaande code berekent de woorden die het meeste voorkomen in de tekst die wordt genoemd in de variabele 'book'. Deze code maakt net als bovenstaande code gebruik van de functie _removeStopWords()_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "book = '03391.txt'\n",
    "\n",
    "freq = calculateWordFrequencies( join( dir , book ) )\n",
    "freq = removeStopwords( freq )\n",
    "\n",
    "sorted_f = sorted( freq , key=lambda x: freq[x])\n",
    "max = 30\n",
    "i = 0\n",
    "\n",
    "for f in reversed( sorted_f ):\n",
    "    i += 1\n",
    "    print( '{} =>  {}'.format( f , freq[f] ) )\n",
    "    if i == max:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De resultaten van de collocatie-analyse en van de berekening van de meest frequente woorden kunnen ook grafisch worden weergegeven. MatPlotLub is een veelgebruikte visualisatie-bibliotheek in Python. De onderstaande code maakt bivendien gebruik van de _wordcloud_-module. Wanneer via een van de bovenstaande blokken een variable met de naam 'freq' is aangemaakt, worden de woorden, op basis van de bijbehorende tellingen, in een woordenwolk weergegeven."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "wordcloud = WordCloud( background_color=\"white\",  width=1500,height=1000, max_words= 100,relative_scaling=1,normalize_plurals=False).generate_from_frequencies(freq)\n",
    "\n",
    "\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

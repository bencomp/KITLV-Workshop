{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KITLV Workshop deel 2\n",
    "\n",
    "\n",
    "Alle teksten in het corpus dat is aangemaakt voor \"Soldaat in IndonesiÃ«\" zijn verrijkt met POS-tags, met lemmas en met waarden die aangeven of woorden positieve of negatieve connotaties hebben. \n",
    "\n",
    "De taalkundige verrijkingen zijn toegevoegd met TreeTagger: http://treetaggerwrapper.readthedocs.io/en/latest/\n",
    "\n",
    "De waarden ten behoeve van de \"sentiment analysis\" zijn toegevoegd via de _DuoMan Subjectivity Lexicon_: https://ivdnt.org/taalmaterialen/102-taalmaterialen/2035-tstc-duoman-subjectivitylexicon\n",
    "\n",
    "De verrijkte bestanden zijn beschikbaar gesteld als TEI-bestanden. Deze gecodeerde bestanden kunnen via de onderstaande code worden gedownload. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "download_corpus(\"https://pino.leidenuniv.nl/kitlv/texts/XMLcorpus.zip\", \"username\", \"password\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In dit deel van de cursus wordt grotendeels met dezelfde modules gewerkt als in deel 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from os.path import isfile, join , isdir\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import xml.etree.ElementTree as ET\n",
    "import requests\n",
    "import zipfile\n",
    "import math\n",
    "import os\n",
    "from os.path import isfile, join , isdir\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from kitlvTdm import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Op basis van de gecodeerd bestanden kan gerichter worden gezocht naar specifieke woord-categorien in de buurt van een opgegeven zoekterm. De functie _collocationPos()_ is een uitbreiding van de collocatie-analyse die in deel 1 van de workshop is besproken. Naast een 'book' (de tekst waar in moet worden gezicht), de 'searchTerm' (de zoekterm) en de 'distance' (het aantal woorden voor en na de gevonden zoekterm; de omvang van de context) moet in deze functie ook een 'Part of Speech'-categorie worden opgegeven. De zoekactie beperkt zich dan tit woorden in de opgegeven categorie. Een overzicht van alle mogelijke POS-categorieen kan hier worden gevonden: http://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/data/dutch-tagset.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freq = dict()\n",
    "freq = collocationPos( join( 'XML' , '03391.xml' ) , 'ambonees' , 20 , 'adj' )\n",
    "\n",
    "## The line below sorts the dictionary by value\n",
    "sorted_f = sorted( freq , key=lambda x: freq[x])\n",
    "\n",
    "## Change the value of 'max' to see more results\n",
    "max = 50\n",
    "i = 0\n",
    "\n",
    "for f in reversed( sorted_f ):\n",
    "    i += 1\n",
    "    print(f)\n",
    "    if i == max:\n",
    "        break\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De code hieronder kan uit een opgegeven boek alle woorden in een bepaalde grammaticale categorie extraheren. Zoeken met de categorie 'nounprop' ('proper name') kan bijvoorbeeld nuttig zijn bij het opsporen van persoonsnamen of plaatsnamen.  \t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "freq = dict()\n",
    "freq = getWordsByPosTag( join( 'XML' , '03395.xml' ) , 'nounprop' )\n",
    "\n",
    "\n",
    "for f in sorted(freq):\n",
    "    print(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aangezien de teksten in het corpus zijn verrijkt met labels die aangeven of woorden een negatieve, neutrale of positieve gevoelswaarde hebben, kunnen verschillende teksten ook op dit vlak met elkaar worden vergeleken. In de code hieronder worden vier teksten geselecteerd. In deze teksten worden de woorden met specifieke gevoelswaarden geteld. De totalen worden grafisch weergegeven in een grafiek, via de _matPlotLib_-module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "xData = []\n",
    "yData = []\n",
    "labels = []\n",
    "\n",
    "dir = 'XML'\n",
    "\n",
    "for file in ( '03391.xml' , '03592.xml' , '03399.xml' , '03794.xml' ):\n",
    "    count = sentimentAnalysis( join( dir , file ) )\n",
    "    xData.append( count['positive'] / count['all'] )\n",
    "    yData.append( count['negative'] / count['all'] )\n",
    "    labels.append( file )\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.scatter(xData,yData,  color='#0a429b', s=30 , marker=\"o\")\n",
    "\n",
    "plt.xlabel('positive')\n",
    "plt.ylabel('negative')\n",
    "plt.title('Words with positive and negative connotation')\n",
    "\n",
    "for i in range( 0 , len(labels) ):\n",
    "    plt.annotate( labels[i] , xy = ( xData[i] , yData[i] ) , xytext=( 0, 10) , textcoords='offset pixels',horizontalalignment='right',verticalalignment='bottom')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De onderstaande code kan worden gebruikt om alle woorden met een positieve connotatie te vinden. Gebruik om alle woorden met een negatieve connotatie te vinden de functie _getNegativeWords()_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "taggedWords = getPositiveWords( join( 'XML' , '03592.xml' ) )\n",
    "                                     \n",
    "for w in taggedWords:\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec is een algoritme dat de woorden die voorkomen in een verzameling van teksten kan voorstellen als een verzameling van vectoren. De dimensies van die vectoren zeggen iets over hoe het woord wordt gebruikt. Vectoren met vergelijkbare dimensies zijn vaak ook semantisch verwant. Om met Word2Vec te kunnen werken moet de module _gensim_ worden geinstalleerd. Het model met 'word embeddings' of 'vectoren' is vooraf aangemaakt en is opgeslagen onder de naam \"egodocumenten.txt\". Dit model moet op de eerste plaats worden ingeleven. Het corpus bestaat uit ca. 30 miljoen woorden, dus het inlezen van dit model kan enige tijd duren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "word2vec_model_file = \"egodocumenten.txt\"\n",
    "ed_model = gensim.models.KeyedVectors.load( word2vec_model_file )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wanneer het Word2Vec model is ingelezen, kunnen de vectoren worden geanalyseerd. Word2Vec kan onder meer worden toegepast om op zoek te gaan naar woorden die op een vergelijkbare manier worden gebruikt. In _gensim_ kan dit via de functie _most_similar()_. Wanneer als parameter van deze functie een woord wordt opgegeven gaat het algoritme, op basis van het aangemaakte model, op zoek naar woorden die op een vergelijkbare manier zijn gebruikt in het corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for word in ('java','soldaat','japanner','molukken'):\n",
    "    if word in ed_model:\n",
    "        print(word,ed_model.most_similar(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dit laatste blok illustreert hoe er met een specifiek lexicon kan worden gezocht. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count = countLexiconWords( join( 'XML' , '03592.xml' ) , 'oorlog.txt' )\n",
    "print( count )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
